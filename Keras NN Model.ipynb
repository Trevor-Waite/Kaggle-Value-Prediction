{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import SGD,RMSprop\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 26\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.read_csv('train_250.csv')\n",
    "test_X = pd.read_csv('test_250.csv')\n",
    "train_y = pd.read_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (4459, 250)\n",
      "Test set size: (49342, 250)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set size: {}\".format(train_X.shape))\n",
    "print(\"Test set size: {}\".format(test_X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leak</th>\n",
       "      <th>log_leak</th>\n",
       "      <th>Var</th>\n",
       "      <th>Max</th>\n",
       "      <th>Std</th>\n",
       "      <th>SumZeros</th>\n",
       "      <th>weight_count</th>\n",
       "      <th>SumValues</th>\n",
       "      <th>srp_6</th>\n",
       "      <th>grp_1</th>\n",
       "      <th>...</th>\n",
       "      <th>400e9303d</th>\n",
       "      <th>e94c03517</th>\n",
       "      <th>64e38e7a2</th>\n",
       "      <th>cbf236577</th>\n",
       "      <th>203c64df6</th>\n",
       "      <th>9a9fc1aba</th>\n",
       "      <th>bdf773176</th>\n",
       "      <th>129fe0263</th>\n",
       "      <th>190db8488</th>\n",
       "      <th>c5dacc85b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.220134</td>\n",
       "      <td>0.966739</td>\n",
       "      <td>-0.122376</td>\n",
       "      <td>-0.204619</td>\n",
       "      <td>-0.228293</td>\n",
       "      <td>0.259388</td>\n",
       "      <td>-0.174264</td>\n",
       "      <td>-0.259388</td>\n",
       "      <td>3.443512</td>\n",
       "      <td>-6.549093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188571</td>\n",
       "      <td>-0.077914</td>\n",
       "      <td>-0.108463</td>\n",
       "      <td>-0.094536</td>\n",
       "      <td>-0.061265</td>\n",
       "      <td>-0.105151</td>\n",
       "      <td>1.162975</td>\n",
       "      <td>-0.119694</td>\n",
       "      <td>-0.265703</td>\n",
       "      <td>-0.099411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.536472</td>\n",
       "      <td>0.256984</td>\n",
       "      <td>-0.125737</td>\n",
       "      <td>-0.164270</td>\n",
       "      <td>-0.275031</td>\n",
       "      <td>0.424440</td>\n",
       "      <td>-0.366371</td>\n",
       "      <td>-0.424440</td>\n",
       "      <td>1.430268</td>\n",
       "      <td>3.883112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188571</td>\n",
       "      <td>-0.077914</td>\n",
       "      <td>-0.108463</td>\n",
       "      <td>-0.094536</td>\n",
       "      <td>-0.061265</td>\n",
       "      <td>-0.105151</td>\n",
       "      <td>-0.150764</td>\n",
       "      <td>-0.119694</td>\n",
       "      <td>-0.265703</td>\n",
       "      <td>-0.099411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.612781</td>\n",
       "      <td>-2.019324</td>\n",
       "      <td>-0.136551</td>\n",
       "      <td>-0.317599</td>\n",
       "      <td>-0.539275</td>\n",
       "      <td>0.655512</td>\n",
       "      <td>-0.483598</td>\n",
       "      <td>-0.655512</td>\n",
       "      <td>1.458660</td>\n",
       "      <td>1.533526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188571</td>\n",
       "      <td>-0.077914</td>\n",
       "      <td>-0.108463</td>\n",
       "      <td>-0.094536</td>\n",
       "      <td>-0.061265</td>\n",
       "      <td>-0.105151</td>\n",
       "      <td>-0.150764</td>\n",
       "      <td>-0.119694</td>\n",
       "      <td>-0.265703</td>\n",
       "      <td>-0.099411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.358417</td>\n",
       "      <td>0.462973</td>\n",
       "      <td>-0.136937</td>\n",
       "      <td>-0.341809</td>\n",
       "      <td>-0.574045</td>\n",
       "      <td>0.636649</td>\n",
       "      <td>-0.530309</td>\n",
       "      <td>-0.636649</td>\n",
       "      <td>1.459675</td>\n",
       "      <td>-1.008095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188571</td>\n",
       "      <td>-0.077914</td>\n",
       "      <td>-0.108463</td>\n",
       "      <td>-0.094536</td>\n",
       "      <td>-0.061265</td>\n",
       "      <td>-0.105151</td>\n",
       "      <td>-0.150764</td>\n",
       "      <td>-0.119694</td>\n",
       "      <td>-0.265703</td>\n",
       "      <td>-0.099411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.612781</td>\n",
       "      <td>-2.019324</td>\n",
       "      <td>-0.133592</td>\n",
       "      <td>-0.214053</td>\n",
       "      <td>-0.425246</td>\n",
       "      <td>0.617786</td>\n",
       "      <td>-0.390725</td>\n",
       "      <td>-0.617786</td>\n",
       "      <td>1.450892</td>\n",
       "      <td>-2.609483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188571</td>\n",
       "      <td>-0.077914</td>\n",
       "      <td>-0.108463</td>\n",
       "      <td>-0.094536</td>\n",
       "      <td>-0.061265</td>\n",
       "      <td>-0.105151</td>\n",
       "      <td>-0.150764</td>\n",
       "      <td>-0.119694</td>\n",
       "      <td>-0.265703</td>\n",
       "      <td>-0.099411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 750 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       leak  log_leak       Var       Max       Std  SumZeros  weight_count  \\\n",
       "0  4.220134  0.966739 -0.122376 -0.204619 -0.228293  0.259388     -0.174264   \n",
       "1 -0.536472  0.256984 -0.125737 -0.164270 -0.275031  0.424440     -0.366371   \n",
       "2 -0.612781 -2.019324 -0.136551 -0.317599 -0.539275  0.655512     -0.483598   \n",
       "3 -0.358417  0.462973 -0.136937 -0.341809 -0.574045  0.636649     -0.530309   \n",
       "4 -0.612781 -2.019324 -0.133592 -0.214053 -0.425246  0.617786     -0.390725   \n",
       "\n",
       "   SumValues     srp_6     grp_1    ...      400e9303d  e94c03517  64e38e7a2  \\\n",
       "0  -0.259388  3.443512 -6.549093    ...      -0.188571  -0.077914  -0.108463   \n",
       "1  -0.424440  1.430268  3.883112    ...      -0.188571  -0.077914  -0.108463   \n",
       "2  -0.655512  1.458660  1.533526    ...      -0.188571  -0.077914  -0.108463   \n",
       "3  -0.636649  1.459675 -1.008095    ...      -0.188571  -0.077914  -0.108463   \n",
       "4  -0.617786  1.450892 -2.609483    ...      -0.188571  -0.077914  -0.108463   \n",
       "\n",
       "   cbf236577  203c64df6  9a9fc1aba  bdf773176  129fe0263  190db8488  c5dacc85b  \n",
       "0  -0.094536  -0.061265  -0.105151   1.162975  -0.119694  -0.265703  -0.099411  \n",
       "1  -0.094536  -0.061265  -0.105151  -0.150764  -0.119694  -0.265703  -0.099411  \n",
       "2  -0.094536  -0.061265  -0.105151  -0.150764  -0.119694  -0.265703  -0.099411  \n",
       "3  -0.094536  -0.061265  -0.105151  -0.150764  -0.119694  -0.265703  -0.099411  \n",
       "4  -0.094536  -0.061265  -0.105151  -0.150764  -0.119694  -0.265703  -0.099411  \n",
       "\n",
       "[5 rows x 750 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Already has standard scaling applied in feature engineering\n",
    "train_X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Keras NN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossfold analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(Dense(200, input_dim=train_X.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    model.add(Dense(200, kernel_initializer='normal', activation='relu'))\n",
    "    \n",
    "    model.add(Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam') #sgd\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2229/2229 [==============================] - 3s 1ms/step - loss: 28.5833\n",
      "Epoch 2/50\n",
      "2229/2229 [==============================] - 1s 536us/step - loss: 6.6689\n",
      "Epoch 3/50\n",
      "2229/2229 [==============================] - 1s 569us/step - loss: 3.6704\n",
      "Epoch 4/50\n",
      "2229/2229 [==============================] - 1s 607us/step - loss: 2.4504\n",
      "Epoch 5/50\n",
      "2229/2229 [==============================] - 1s 515us/step - loss: 2.0045\n",
      "Epoch 6/50\n",
      "2229/2229 [==============================] - 1s 562us/step - loss: 2.1180\n",
      "Epoch 7/50\n",
      "2229/2229 [==============================] - 1s 576us/step - loss: 2.1431\n",
      "Epoch 8/50\n",
      "2229/2229 [==============================] - 1s 518us/step - loss: 1.7981\n",
      "Epoch 9/50\n",
      "2229/2229 [==============================] - 1s 535us/step - loss: 1.7788\n",
      "Epoch 10/50\n",
      "2229/2229 [==============================] - 1s 611us/step - loss: 1.9015\n",
      "Epoch 11/50\n",
      "2229/2229 [==============================] - 1s 527us/step - loss: 1.6467\n",
      "Epoch 12/50\n",
      "2229/2229 [==============================] - 1s 544us/step - loss: 1.5087\n",
      "Epoch 13/50\n",
      "2229/2229 [==============================] - 1s 542us/step - loss: 1.5961\n",
      "Epoch 14/50\n",
      "2229/2229 [==============================] - 1s 598us/step - loss: 1.5187\n",
      "Epoch 15/50\n",
      "2229/2229 [==============================] - 1s 557us/step - loss: 1.4468\n",
      "Epoch 16/50\n",
      "2229/2229 [==============================] - 1s 526us/step - loss: 1.4964\n",
      "Epoch 17/50\n",
      "2229/2229 [==============================] - 1s 566us/step - loss: 1.5723\n",
      "Epoch 18/50\n",
      "2229/2229 [==============================] - 1s 514us/step - loss: 1.4419\n",
      "Epoch 19/50\n",
      "2229/2229 [==============================] - 1s 558us/step - loss: 1.2399\n",
      "Epoch 20/50\n",
      "2229/2229 [==============================] - 1s 522us/step - loss: 1.2278\n",
      "Epoch 21/50\n",
      "2229/2229 [==============================] - 1s 526us/step - loss: 1.2380\n",
      "Epoch 22/50\n",
      "2229/2229 [==============================] - 1s 562us/step - loss: 1.0646\n",
      "Epoch 23/50\n",
      "2229/2229 [==============================] - 1s 532us/step - loss: 1.2363\n",
      "Epoch 24/50\n",
      "2229/2229 [==============================] - 1s 605us/step - loss: 1.1143\n",
      "Epoch 25/50\n",
      "2229/2229 [==============================] - 1s 533us/step - loss: 1.0122\n",
      "Epoch 26/50\n",
      "2229/2229 [==============================] - 1s 526us/step - loss: 0.9489\n",
      "Epoch 27/50\n",
      "2229/2229 [==============================] - 1s 526us/step - loss: 0.9156\n",
      "Epoch 28/50\n",
      "2229/2229 [==============================] - 1s 581us/step - loss: 0.9395\n",
      "Epoch 29/50\n",
      "2229/2229 [==============================] - 1s 534us/step - loss: 0.9284\n",
      "Epoch 30/50\n",
      "2229/2229 [==============================] - 1s 550us/step - loss: 0.8746\n",
      "Epoch 31/50\n",
      "2229/2229 [==============================] - 1s 558us/step - loss: 0.8810\n",
      "Epoch 32/50\n",
      "2229/2229 [==============================] - 1s 561us/step - loss: 0.8959\n",
      "Epoch 33/50\n",
      "2229/2229 [==============================] - 1s 552us/step - loss: 0.8219\n",
      "Epoch 34/50\n",
      "2229/2229 [==============================] - 1s 546us/step - loss: 0.8833\n",
      "Epoch 35/50\n",
      "2229/2229 [==============================] - 1s 532us/step - loss: 0.9148\n",
      "Epoch 36/50\n",
      "2229/2229 [==============================] - 1s 527us/step - loss: 0.7814\n",
      "Epoch 37/50\n",
      "2229/2229 [==============================] - 1s 534us/step - loss: 0.8430\n",
      "Epoch 38/50\n",
      "2229/2229 [==============================] - 1s 527us/step - loss: 0.7234\n",
      "Epoch 39/50\n",
      "2229/2229 [==============================] - 2s 675us/step - loss: 0.6495\n",
      "Epoch 40/50\n",
      "2229/2229 [==============================] - 2s 1ms/step - loss: 0.6464\n",
      "Epoch 41/50\n",
      "2229/2229 [==============================] - 2s 1ms/step - loss: 0.6680\n",
      "Epoch 42/50\n",
      "2229/2229 [==============================] - 2s 1ms/step - loss: 0.7108\n",
      "Epoch 43/50\n",
      "2229/2229 [==============================] - 2s 1ms/step - loss: 0.7716\n",
      "Epoch 44/50\n",
      "2229/2229 [==============================] - 2s 1ms/step - loss: 0.7462\n",
      "Epoch 45/50\n",
      "2229/2229 [==============================] - 2s 1ms/step - loss: 0.6875\n",
      "Epoch 46/50\n",
      "2229/2229 [==============================] - 2s 1ms/step - loss: 0.6316\n",
      "Epoch 47/50\n",
      "2229/2229 [==============================] - 2s 1ms/step - loss: 0.6370\n",
      "Epoch 48/50\n",
      "2229/2229 [==============================] - 2s 1ms/step - loss: 0.5638\n",
      "Epoch 49/50\n",
      "2229/2229 [==============================] - 2s 1ms/step - loss: 0.5323\n",
      "Epoch 50/50\n",
      "2229/2229 [==============================] - 2s 1ms/step - loss: 0.5216\n",
      "2230/2230 [==============================] - 3s 1ms/step\n",
      "Epoch 1/50\n",
      "2230/2230 [==============================] - 6s 3ms/step - loss: 26.4647\n",
      "Epoch 2/50\n",
      "2230/2230 [==============================] - 2s 813us/step - loss: 6.3368\n",
      "Epoch 3/50\n",
      "2230/2230 [==============================] - 1s 533us/step - loss: 3.6689\n",
      "Epoch 4/50\n",
      "2230/2230 [==============================] - 1s 575us/step - loss: 2.5531\n",
      "Epoch 5/50\n",
      "2230/2230 [==============================] - 1s 584us/step - loss: 1.9700\n",
      "Epoch 6/50\n",
      "2230/2230 [==============================] - 1s 572us/step - loss: 1.7011\n",
      "Epoch 7/50\n",
      "2230/2230 [==============================] - 1s 538us/step - loss: 1.7634\n",
      "Epoch 8/50\n",
      "2230/2230 [==============================] - 1s 545us/step - loss: 1.6012\n",
      "Epoch 9/50\n",
      "2230/2230 [==============================] - 1s 640us/step - loss: 1.7299\n",
      "Epoch 10/50\n",
      "2230/2230 [==============================] - 1s 589us/step - loss: 1.5999\n",
      "Epoch 11/50\n",
      "2230/2230 [==============================] - 1s 599us/step - loss: 1.6898\n",
      "Epoch 12/50\n",
      "2230/2230 [==============================] - 1s 577us/step - loss: 1.5267\n",
      "Epoch 13/50\n",
      "2230/2230 [==============================] - 1s 560us/step - loss: 1.5305\n",
      "Epoch 14/50\n",
      "2230/2230 [==============================] - 1s 573us/step - loss: 1.4490\n",
      "Epoch 15/50\n",
      "2230/2230 [==============================] - 1s 595us/step - loss: 1.2728\n",
      "Epoch 16/50\n",
      "2230/2230 [==============================] - 1s 634us/step - loss: 1.4245\n",
      "Epoch 17/50\n",
      "2230/2230 [==============================] - 1s 569us/step - loss: 1.2089\n",
      "Epoch 18/50\n",
      "2230/2230 [==============================] - 1s 595us/step - loss: 1.2329\n",
      "Epoch 19/50\n",
      "2230/2230 [==============================] - 1s 659us/step - loss: 1.4085\n",
      "Epoch 20/50\n",
      "2230/2230 [==============================] - 1s 588us/step - loss: 1.2762\n",
      "Epoch 21/50\n",
      "2230/2230 [==============================] - 1s 534us/step - loss: 1.1485\n",
      "Epoch 22/50\n",
      "2230/2230 [==============================] - 1s 561us/step - loss: 1.0485\n",
      "Epoch 23/50\n",
      "2230/2230 [==============================] - 1s 564us/step - loss: 1.0940\n",
      "Epoch 24/50\n",
      "2230/2230 [==============================] - 1s 530us/step - loss: 1.1484\n",
      "Epoch 25/50\n",
      "2230/2230 [==============================] - 1s 563us/step - loss: 1.1139\n",
      "Epoch 26/50\n",
      "2230/2230 [==============================] - 1s 521us/step - loss: 1.1841\n",
      "Epoch 27/50\n",
      "2230/2230 [==============================] - 1s 516us/step - loss: 0.9754\n",
      "Epoch 28/50\n",
      "2230/2230 [==============================] - 1s 572us/step - loss: 0.9062\n",
      "Epoch 29/50\n",
      "2230/2230 [==============================] - 1s 534us/step - loss: 0.8092\n",
      "Epoch 30/50\n",
      "2230/2230 [==============================] - 1s 519us/step - loss: 0.8312\n",
      "Epoch 31/50\n",
      "2230/2230 [==============================] - 1s 538us/step - loss: 0.9352\n",
      "Epoch 32/50\n",
      "2230/2230 [==============================] - 1s 556us/step - loss: 0.9409\n",
      "Epoch 33/50\n",
      "2230/2230 [==============================] - 1s 575us/step - loss: 0.8383\n",
      "Epoch 34/50\n",
      "2230/2230 [==============================] - 1s 530us/step - loss: 0.7607\n",
      "Epoch 35/50\n",
      "2230/2230 [==============================] - 1s 527us/step - loss: 0.7421\n",
      "Epoch 36/50\n",
      "2230/2230 [==============================] - 1s 630us/step - loss: 0.7644\n",
      "Epoch 37/50\n",
      "2230/2230 [==============================] - 1s 570us/step - loss: 0.7849\n",
      "Epoch 38/50\n",
      "2230/2230 [==============================] - 1s 656us/step - loss: 0.7542\n",
      "Epoch 39/50\n",
      "2230/2230 [==============================] - 1s 595us/step - loss: 0.8057\n",
      "Epoch 40/50\n",
      "2230/2230 [==============================] - 1s 598us/step - loss: 0.6819\n",
      "Epoch 41/50\n",
      "2230/2230 [==============================] - 1s 569us/step - loss: 0.6143\n",
      "Epoch 42/50\n",
      "2230/2230 [==============================] - 1s 547us/step - loss: 0.6041\n",
      "Epoch 43/50\n",
      "2230/2230 [==============================] - 1s 554us/step - loss: 0.6221\n",
      "Epoch 44/50\n",
      "2230/2230 [==============================] - 1s 667us/step - loss: 0.6342\n",
      "Epoch 45/50\n",
      "2230/2230 [==============================] - 1s 583us/step - loss: 0.6312\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2230/2230 [==============================] - 1s 526us/step - loss: 0.6121\n",
      "Epoch 47/50\n",
      "2230/2230 [==============================] - 1s 550us/step - loss: 0.6962\n",
      "Epoch 48/50\n",
      "2230/2230 [==============================] - 1s 538us/step - loss: 0.6081\n",
      "Epoch 49/50\n",
      "2230/2230 [==============================] - 1s 591us/step - loss: 0.5783\n",
      "Epoch 50/50\n",
      "2230/2230 [==============================] - 1s 538us/step - loss: 0.5988\n",
      "2229/2229 [==============================] - 1s 621us/step\n",
      "Results: 1.94 (0.26) RMSE\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=2, random_state=seed)\n",
    "results = cross_val_score(estimator, \n",
    "                          train_X, \n",
    "                          train_y, \n",
    "                          cv=kfold, scoring=\"mean_squared_error\")\n",
    "\n",
    "print(\"Results: %.2f (%.2f) RMSE\" % (np.sqrt(-results.mean()), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Val Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEED TO BEAT 0.61\n",
    "\n",
    "@ 2 fold cross val, 50 epochs, 32 batch size, adam, relu\n",
    "Baseline - 2.4 RMSE\n",
    "Wide 1500 - 3.22 RMSE\n",
    "Deep 750 -> 300 - 2.42 RMSE\n",
    "Deep 750 -> 200 - 2.33 RMSE\n",
    "Deep 750 -> 100 - 2.42 RMSE\n",
    "Deep 750 -> 150 - 2.37 RMSE\n",
    "\n",
    "\n",
    "750 ->200/200 - 2.38\n",
    "750 ->200/200/200 - 2.31\n",
    "750 ->200/200/200/200 - 2.27\n",
    "750 ->200/200/200/200 200/200/200/200- 2.17\n",
    "\n",
    "all_features -> 200 - 3.62 @ 10 epochs SLOW AF\n",
    "\n",
    "500 -> 200 - 2.26 @ batch size 32\n",
    "500 -> 200 -  2.20 @ batch size 25\n",
    "500 -> 200 -  2.11 @ batch size 15\n",
    "500 -> 200 -  2.00 @ batch size 10\n",
    "\n",
    "500 -> 200 -  2.06 @ batch size 10 w/ batchnormalization\n",
    "\n",
    "@batch size 10, 50 epochs\n",
    "200 -> 200 - 1.99\n",
    "200 -> 200 -> 50 - 1.94\n",
    "200 * 8 - 1.5\n",
    "200 * 8 -> 50 - 1.3\n",
    "200 * 16 -> 50 - 1.29\n",
    "200 * 8 -> 100 -> 50 -> 10 - 1.96\n",
    "\n",
    "200 * 8 -> 10 - 1.75\n",
    "\n",
    "200 * 8 -> 100 - 1.2\n",
    "\n",
    "200 * 32 -> 100 - 1.18\n",
    "\n",
    "200 * 8 -> 100 - 1.17 (250 features)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "    \n",
    "model.add(Dense(200, input_dim=train_X.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "for i in range(1,8):\n",
    "    model.add(Dense(200, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(100, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "model.compile(loss='mean_squared_error', optimizer='adam') #sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3344 samples, validate on 1115 samples\n",
      "Epoch 1/50\n",
      "3344/3344 [==============================] - 13s 4ms/step - loss: 32.8891 - val_loss: 8.8963\n",
      "Epoch 2/50\n",
      "3344/3344 [==============================] - 7s 2ms/step - loss: 7.0352 - val_loss: 5.6772\n",
      "Epoch 3/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 3.2924 - val_loss: 3.6004\n",
      "Epoch 4/50\n",
      "3344/3344 [==============================] - 7s 2ms/step - loss: 2.5277 - val_loss: 4.6638\n",
      "Epoch 5/50\n",
      "3344/3344 [==============================] - 10s 3ms/step - loss: 2.1583 - val_loss: 2.5523\n",
      "Epoch 6/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 1.7342 - val_loss: 4.9850\n",
      "Epoch 7/50\n",
      "3344/3344 [==============================] - 10s 3ms/step - loss: 1.7605 - val_loss: 2.1183\n",
      "Epoch 8/50\n",
      "3344/3344 [==============================] - 10s 3ms/step - loss: 1.4497 - val_loss: 1.8895\n",
      "Epoch 9/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 1.4574 - val_loss: 1.8876\n",
      "Epoch 10/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 1.3788 - val_loss: 2.1999\n",
      "Epoch 11/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 1.2167 - val_loss: 1.8497\n",
      "Epoch 12/50\n",
      "3344/3344 [==============================] - 7s 2ms/step - loss: 1.1686 - val_loss: 1.7503\n",
      "Epoch 13/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 1.0461 - val_loss: 2.0880\n",
      "Epoch 14/50\n",
      "3344/3344 [==============================] - 10s 3ms/step - loss: 1.0791 - val_loss: 1.5496\n",
      "Epoch 15/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 1.0625 - val_loss: 1.7408\n",
      "Epoch 16/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 0.9923 - val_loss: 1.5865\n",
      "Epoch 17/50\n",
      "3344/3344 [==============================] - 10s 3ms/step - loss: 0.8615 - val_loss: 2.2858\n",
      "Epoch 18/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 0.7925 - val_loss: 2.0105\n",
      "Epoch 19/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 0.7458 - val_loss: 1.5369\n",
      "Epoch 20/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 0.8080 - val_loss: 1.4503\n",
      "Epoch 21/50\n",
      "3344/3344 [==============================] - 10s 3ms/step - loss: 0.6248 - val_loss: 1.4046\n",
      "Epoch 22/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 0.6595 - val_loss: 1.5412\n",
      "Epoch 23/50\n",
      "3344/3344 [==============================] - 10s 3ms/step - loss: 0.6520 - val_loss: 1.7872\n",
      "Epoch 24/50\n",
      "3344/3344 [==============================] - 10s 3ms/step - loss: 0.7472 - val_loss: 1.5718\n",
      "Epoch 25/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 0.6246 - val_loss: 1.5118\n",
      "Epoch 26/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 0.5048 - val_loss: 1.5848\n",
      "Epoch 27/50\n",
      "3344/3344 [==============================] - 7s 2ms/step - loss: 0.5096 - val_loss: 1.5069\n",
      "Epoch 28/50\n",
      "3344/3344 [==============================] - 10s 3ms/step - loss: 0.5070 - val_loss: 1.4553\n",
      "Epoch 29/50\n",
      "3344/3344 [==============================] - 10s 3ms/step - loss: 0.5731 - val_loss: 1.4016\n",
      "Epoch 30/50\n",
      "3344/3344 [==============================] - 7s 2ms/step - loss: 0.5339 - val_loss: 1.4087\n",
      "Epoch 31/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 0.4672 - val_loss: 1.3661\n",
      "Epoch 32/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 0.4574 - val_loss: 1.4685\n",
      "Epoch 33/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 0.4646 - val_loss: 1.2214\n",
      "Epoch 34/50\n",
      "3344/3344 [==============================] - 8s 3ms/step - loss: 0.4911 - val_loss: 1.2605\n",
      "Epoch 35/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 0.4354 - val_loss: 1.2460\n",
      "Epoch 36/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 0.4337 - val_loss: 1.3449\n",
      "Epoch 37/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 0.4100 - val_loss: 1.2976\n",
      "Epoch 38/50\n",
      "3344/3344 [==============================] - 8s 3ms/step - loss: 0.4519 - val_loss: 1.1795\n",
      "Epoch 39/50\n",
      "3344/3344 [==============================] - 8s 3ms/step - loss: 0.4046 - val_loss: 1.3030\n",
      "Epoch 40/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 0.3811 - val_loss: 1.2777\n",
      "Epoch 41/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 0.3567 - val_loss: 1.1593\n",
      "Epoch 42/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 0.3385 - val_loss: 1.2610\n",
      "Epoch 43/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 0.3409 - val_loss: 1.3927\n",
      "Epoch 44/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 0.4061 - val_loss: 1.3512\n",
      "Epoch 45/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 0.3888 - val_loss: 1.3696\n",
      "Epoch 46/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 0.4313 - val_loss: 1.1715\n",
      "Epoch 47/50\n",
      "3344/3344 [==============================] - 8s 3ms/step - loss: 0.3656 - val_loss: 1.2212\n",
      "Epoch 48/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 0.3782 - val_loss: 1.1765\n",
      "Epoch 49/50\n",
      "3344/3344 [==============================] - 9s 3ms/step - loss: 0.3157 - val_loss: 1.1857\n",
      "Epoch 50/50\n",
      "3344/3344 [==============================] - 8s 2ms/step - loss: 0.3141 - val_loss: 1.3830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2198d2b9278>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_tr,y_tr,validation_data=(X_val,y_val),nb_epoch=50,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115/1115 [==============================] - 0s 305us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1760197716709695"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(model.evaluate(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data() :\n",
    "X, Y = [], []\n",
    "for x in xrange(1000) :\n",
    "X.append(np.random.random_sample(5,))\n",
    "Y.append(np.random.random_sample())\n",
    "return np.asarray(X), np.asarray(Y)\n",
    "def temp_data() :\n",
    "X, Y = [], []\n",
    "for x in xrange(1000) :\n",
    "sample = []\n",
    "for x in xrange(4) :\n",
    "sample.append(np.random.random_sample(5,))\n",
    "X.append(sample)\n",
    "Y.append(np.random.random_sample())\n",
    "return np.asarray(X), np.asarray(Y)\n",
    "if name == 'main':\n",
    "X,Y = temp_data()\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, 10, activation='sigmoid', inner_activation='hard_sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,1, init='uniform', activation='linear'))\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
